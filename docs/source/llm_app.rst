================
LLM applications
================
Large language models (LLMs) have demonstrated remarkable capabilities in various domains. However, building a real-world application with LLMs can be challenging due to their hallucinations and outdated knowledge. To address these issues, retrieval-augmented generation (RAG) and agentic AI have been employed. In this note, we will introduce them and provide a hands-on recipe to build a AI assistant and a AI scientist.

LLM and its limitations
------------------------
LLMs are capable of generating text that is coherent and contextually relevant. However, they are prone to hallucination, which means they may generate text that is not based on factual evidence or prior knowledge. This can lead to inaccurate or misleading information being generated by the model.

Especially for knowledge-intensive tasks, LLMs are not sufficient. To address this, RAG is proposed. Besides, some tasks requires reasoning and other tools (e.g., code interpreter) are often hard to complete by LLMs alone. To address this, agentic AI is proposed.

.. figure:: ./images/llm_app1.png
    :align: center
    :alt: Ray Cluster Architecture

    LLM applications

RAG
----
RAG aims to leverage the external knowledge to help LLM answer questions. It consists of two components: a retriever and a generator. The retriever is responsible for retrieving relevant documents from a knowledge base, while the generator is responsible for generating the answer based on the retrieved documents.

.. figure:: https://weaviate.io/assets/images/Vanilla_RAG-697535e2d5b9ae64ccfd6415a79965c7.png
    :align: center
    :alt: Ray Cluster Architecture

    RAG workflow (`Weaviate <https://weaviate.io/blog/retrieval-augmented-generation/>`_)

Fine-tuning vs. RAG
^^^^^^^^^^^^^^^^^^^^
A strightforward approach to improve LLMs is fine-tuning. However, fine-tuning requires a large amount of labeled data and is computationally expensive. In contrast, RAG provides a more efficient way to **inject new knowledge** into LLMs. 

Measurements of RAG
^^^^^^^^^^^^^^^^^^^^
Based on the workflow of RAG, we often measure the performance from two aspects: the quality of the retrieved documents and the quality of the generated answer.

.. figure:: ./images/ragchecker_metrics.png
    :align: center
    :alt: Ray Cluster Architecture

    RAGChecker Metrics (`RAGChecker <https://github.com/ragchecker/ragchecker>`_)

Challenges for RAG
^^^^^^^^^^^^^^^^^^^^
1. **Unreliable information retrieval**: LLMs are sensistive to the provided context information. Irrelevant or misleading retrieval results can lead to poor performance.
    - Misleading user queries
    - Wrong ranks of retrieved documents
2. **Time-consuming inference**: retrieval will add additional time to the inference process.
    - Iterative retrievals

Recent advancements
^^^^^^^^^^^^^^^^^^^^

**Graph-based RAG** employs a knowledge graph to improve the retrieval process. It can reduce the number of retrieved documents and improve the quality of the retrieved documents. Popular implementations include `GraphRAG <https://github.com/microsoft/graphrag>`_ and `LightRAG <https://github.com/HKUDS/LightRAG>`_.

**Self-RAG** (`Asai et al. <https://arxiv.org/abs/2310.11511>`_) uses a tuned LLM to decide whether to retrieve documents or not and whether the retrieval results are reliable. It boost naive RAG by more than 10% in accuracy.

**Agentic RAG** extends Self-RAG to multi-agent systems. It decompose user queries into sub-queries and assign different agents to handle different sub-queries. It can handle more complex tasks and improve the performance of RAG.

.. figure:: https://weaviate.io/assets/images/Multi_Agent_RAG_System-73e480f62a52e172a78a0ac344dcdcb5.png
    :align: center
    :alt: Ray Cluster Architecture

    Multi-agent RAG (`Weaviate. <https://weaviate.io/blog/what-is-agentic-rag>`_)

Agentic AI
-----------
Agentic AI (`Lilian Weng. <https://lilianweng.github.io/posts/2023-06-23-agent/>`_) powered by LLMs uses LLMs as a controller to complete tasks. It consists of four components: planer, memory, tool use, and action.

.. figure:: https://lilianweng.github.io/posts/2023-06-23-agent/agent-overview.png
    :align: center
    :alt: Ray Cluster Architecture

    Agent overview

**Single agent** xxx

**Multi-agent AI** xxx

Recipe for AI assistant
------------------------
This tutorial will guide you through building a AI assistant using `LlamaIndex <https://github.com/run-llama/llama_index>`_.

Recipe for AI scientist
------------------------
This tutorial will guide you through building a AI scientist using `CrewAI <https://github.com/crewAIInc/crewAI>`_.


References
-----------
1. Microsoft. `"GraphRAG" <https://github.com/microsoft/graphrag>`_ Github repo.
2. HKUDS. `"LightRAG" <https://github.com/HKUDS/LightRAG>`_ Github repo.
3. Asai et al. `"Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection" <https://arxiv.org/abs/2310.11511>`_ ICLR 2024.
4. Lilian Weng. `"LLM Powered Autonomous Agents" <https://lilianweng.github.io/posts/2023-06-23-agent/>`_ Tech blog (2023).