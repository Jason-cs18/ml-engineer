================
LLM applications
================
Large language models (LLMs) have demonstrated remarkable capabilities in various domains. However, building a real-world application with LLMs can be challenging due to their hallucinations and outdated knowledge. To address these issues, retrieval-augmented generation (RAG) and agentic AI have been employed. In this note, we will introduce them and provide a hands-on recipe to build a AI assistant and a AI scientist.

LLM and its limitations
------------------------

RAG
----

Fine-tuning vs. RAG
^^^^^^^^^^^^^^^^^^^^

Measurements of RAG
^^^^^^^^^^^^^^^^^^^^

Challenges for RAG
^^^^^^^^^^^^^^^^^^^^

Advancedments in RAG
^^^^^^^^^^^^^^^^^^^^

**Self-RAG** (`Asai et al. <https://arxiv.org/abs/2310.11511>`_)

**Graph-based RAG** xxx

**Agentic RAG** xxx

Agentic AI
-----------

**Single agent** xxx

**Multi-agent AI** xxx

Recipe for AI assistant
------------------------
This tutorial will guide you through building a AI assistant using `LlamaIndex <https://github.com/run-llama/llama_index>`_.

Recipe for AI scientist
------------------------
This tutorial will guide you through building a AI scientist using `CrewAI <https://github.com/crewAIInc/crewAI>`_.


References
-----------