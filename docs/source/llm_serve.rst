===============
LLM serving
===============

Large language models (LLMs) have demonstrated remarkable capabilieties in various natural language processing tasks. However, deploying these models for real-world applications can be challenging due to their high computational requirements and the need for efficient serving infrastructure.

On this note, we summarize two popular inference engines for LLMs: `vLLM <https://github.com/vllm-project/vllm>`_ and `SGLang <https://github.com/sgl-project/sglang>`_.

vLLM
----

Installation
^^^^^^^^^^^^^^^^^^

use `vLLM <https://github.com/vllm-project/vllm>`_ to serve LLMs.
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

SGLang
-------

Installation
^^^^^^^^^^^^^^^^^^

use `SGLang <https://github.com/sgl-project/sglang>`_ to serve LLMs.
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^